{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8199099,"sourceType":"datasetVersion","datasetId":4856971},{"sourceId":8199233,"sourceType":"datasetVersion","datasetId":4857068}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/openai/whisper.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T22:09:35.637746Z","iopub.execute_input":"2024-04-22T22:09:35.638098Z","iopub.status.idle":"2024-04-22T22:09:37.807990Z","shell.execute_reply.started":"2024-04-22T22:09:35.638068Z","shell.execute_reply":"2024-04-22T22:09:37.806926Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'whisper'...\nremote: Enumerating objects: 712, done.\u001b[K\nremote: Counting objects: 100% (10/10), done.\u001b[K\nremote: Compressing objects: 100% (10/10), done.\u001b[K\nremote: Total 712 (delta 1), reused 3 (delta 0), pack-reused 702\u001b[K\nReceiving objects: 100% (712/712), 12.43 MiB | 26.85 MiB/s, done.\nResolving deltas: 100% (419/419), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/AI4Bharat/vistaar.git","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:11:46.967489Z","iopub.execute_input":"2024-04-22T22:11:46.967878Z","iopub.status.idle":"2024-04-22T22:11:48.239914Z","shell.execute_reply.started":"2024-04-22T22:11:46.967844Z","shell.execute_reply":"2024-04-22T22:11:48.238745Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'vistaar'...\nremote: Enumerating objects: 157, done.\u001b[K\nremote: Counting objects: 100% (12/12), done.\u001b[K\nremote: Compressing objects: 100% (12/12), done.\u001b[K\nremote: Total 157 (delta 4), reused 0 (delta 0), pack-reused 145\u001b[K\nReceiving objects: 100% (157/157), 58.72 KiB | 1.50 MiB/s, done.\nResolving deltas: 100% (89/89), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/belambert/asr-evaluation.git","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:12:00.640368Z","iopub.execute_input":"2024-04-22T22:12:00.641315Z","iopub.status.idle":"2024-04-22T22:12:01.916054Z","shell.execute_reply.started":"2024-04-22T22:12:00.641278Z","shell.execute_reply":"2024-04-22T22:12:01.914959Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'asr-evaluation'...\nremote: Enumerating objects: 494, done.\u001b[K\nremote: Counting objects: 100% (51/51), done.\u001b[K\nremote: Compressing objects: 100% (37/37), done.\u001b[K\nremote: Total 494 (delta 19), reused 35 (delta 9), pack-reused 443\u001b[K\nReceiving objects: 100% (494/494), 115.72 KiB | 2.10 MiB/s, done.\nResolving deltas: 100% (253/253), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r whisper/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:12:12.053613Z","iopub.execute_input":"2024-04-22T22:12:12.054378Z","iopub.status.idle":"2024-04-22T22:12:32.065221Z","shell.execute_reply.started":"2024-04-22T22:12:12.054343Z","shell.execute_reply":"2024-04-22T22:12:32.064266Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from -r whisper/requirements.txt (line 1)) (0.58.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r whisper/requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r whisper/requirements.txt (line 3)) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r whisper/requirements.txt (line 4)) (4.66.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from -r whisper/requirements.txt (line 5)) (10.2.0)\nCollecting tiktoken (from -r whisper/requirements.txt (line 6))\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting triton<3,>=2.0.0 (from -r whisper/requirements.txt (line 7))\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->-r whisper/requirements.txt (line 1)) (0.41.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r whisper/requirements.txt (line 3)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r whisper/requirements.txt (line 3)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r whisper/requirements.txt (line 3)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r whisper/requirements.txt (line 3)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r whisper/requirements.txt (line 3)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r whisper/requirements.txt (line 3)) (2024.2.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r whisper/requirements.txt (line 6)) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r whisper/requirements.txt (line 6)) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r whisper/requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r whisper/requirements.txt (line 6)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r whisper/requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->-r whisper/requirements.txt (line 6)) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r whisper/requirements.txt (line 3)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r whisper/requirements.txt (line 3)) (1.3.0)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, tiktoken\nSuccessfully installed tiktoken-0.6.0 triton-2.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r asr-evaluation/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:12:49.792232Z","iopub.execute_input":"2024-04-22T22:12:49.793132Z","iopub.status.idle":"2024-04-22T22:13:03.862410Z","shell.execute_reply.started":"2024-04-22T22:12:49.793100Z","shell.execute_reply":"2024-04-22T22:13:03.861437Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting edit_distance (from -r asr-evaluation/requirements.txt (line 1))\n  Downloading edit_distance-1.0.6-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from -r asr-evaluation/requirements.txt (line 2)) (2.4.0)\nRequirement already satisfied: flake8 in /opt/conda/lib/python3.10/site-packages (from -r asr-evaluation/requirements.txt (line 3)) (7.0.0)\nRequirement already satisfied: mccabe<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from flake8->-r asr-evaluation/requirements.txt (line 3)) (0.7.0)\nRequirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from flake8->-r asr-evaluation/requirements.txt (line 3)) (2.11.1)\nRequirement already satisfied: pyflakes<3.3.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from flake8->-r asr-evaluation/requirements.txt (line 3)) (3.2.0)\nDownloading edit_distance-1.0.6-py3-none-any.whl (11 kB)\nInstalling collected packages: edit_distance\nSuccessfully installed edit_distance-1.0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r vistaar/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:13:03.864391Z","iopub.execute_input":"2024-04-22T22:13:03.864709Z","iopub.status.idle":"2024-04-22T22:15:06.882998Z","shell.execute_reply.started":"2024-04-22T22:13:03.864680Z","shell.execute_reply":"2024-04-22T22:15:06.881967Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/yt-dlp/yt-dlp.git (from -r vistaar/requirements.txt (line 6))\n  Cloning https://github.com/yt-dlp/yt-dlp.git to /tmp/pip-req-build-t4vdvpg0\n  Running command git clone --filter=blob:none --quiet https://github.com/yt-dlp/yt-dlp.git /tmp/pip-req-build-t4vdvpg0\n  Resolved https://github.com/yt-dlp/yt-dlp.git to commit 89f535e2656964b4061c25a7739d4d6ba0a30568\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting git+https://github.com/huggingface/transformers (from -r vistaar/requirements.txt (line 7))\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-xa714r1k\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-xa714r1k\n  Resolved https://github.com/huggingface/transformers to commit e74d793a3c3c0bc9bf3fb94bb31dd16934b1b0db\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting git+https://github.com/huggingface/datasets (from -r vistaar/requirements.txt (line 8))\n  Cloning https://github.com/huggingface/datasets to /tmp/pip-req-build-89eaia_s\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datasets /tmp/pip-req-build-89eaia_s\n  Resolved https://github.com/huggingface/datasets to commit f96e74d5c633cd5435dd526adb4a74631eb05c43\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting git+https://github.com/anoopkunchukuttan/indic_nlp_library.git (from -r vistaar/requirements.txt (line 9))\n  Cloning https://github.com/anoopkunchukuttan/indic_nlp_library.git to /tmp/pip-req-build-k4bunp74\n  Running command git clone --filter=blob:none --quiet https://github.com/anoopkunchukuttan/indic_nlp_library.git /tmp/pip-req-build-k4bunp74\n  Resolved https://github.com/anoopkunchukuttan/indic_nlp_library.git to commit 4cead0ae6c78fe9a19a51ef679f586206df9c476\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 1)) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 2)) (4.66.1)\nCollecting webrtcvad==2.0.10 (from -r vistaar/requirements.txt (line 3))\n  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m767.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting youtube-dl==2021.6.6 (from -r vistaar/requirements.txt (line 4))\n  Downloading youtube_dl-2021.6.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: pydub==0.25.1 in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 5)) (0.25.1)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 10)) (2.1.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 11)) (2.1.2)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 12)) (0.10.1)\nCollecting jiwer (from -r vistaar/requirements.txt (line 13))\n  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\nCollecting evaluate>=0.3 (from -r vistaar/requirements.txt (line 14))\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 15)) (10.2.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 16)) (2.15.1)\nCollecting deepspeed (from -r vistaar/requirements.txt (line 17))\n  Downloading deepspeed-0.14.1.tar.gz (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r vistaar/requirements.txt (line 18)) (0.29.3)\nRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (1.0.9)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (2024.2.2)\nCollecting mutagen (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6))\n  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\nCollecting pycryptodomex (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6))\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: requests<3,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (2.31.0)\nRequirement already satisfied: urllib3<3,>=1.26.17 in /opt/conda/lib/python3.10/site-packages (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (6.0.1)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7))\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (0.4.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (3.9.1)\nCollecting sphinx-argparse (from indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinx_argparse-0.4.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: sphinx_rtd_theme in /opt/conda/lib/python3.10/site-packages (from indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9)) (0.2.4)\nCollecting morfessor (from indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->-r vistaar/requirements.txt (line 10)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->-r vistaar/requirements.txt (line 10)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->-r vistaar/requirements.txt (line 10)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->-r vistaar/requirements.txt (line 10)) (3.1.2)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (1.4.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (0.58.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (0.3.7)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->-r vistaar/requirements.txt (line 12)) (1.0.7)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer->-r vistaar/requirements.txt (line 13)) (8.1.7)\nCollecting rapidfuzz<4,>=3 (from jiwer->-r vistaar/requirements.txt (line 13))\n  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting responses<0.19 (from evaluate>=0.3->-r vistaar/requirements.txt (line 14))\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r vistaar/requirements.txt (line 16)) (3.0.2)\nCollecting hjson (from deepspeed->-r vistaar/requirements.txt (line 17))\n  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r vistaar/requirements.txt (line 17)) (1.11.1.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r vistaar/requirements.txt (line 17)) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r vistaar/requirements.txt (line 17)) (9.0.0)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r vistaar/requirements.txt (line 17)) (2.5.3)\nRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r vistaar/requirements.txt (line 17)) (11.4.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (4.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r vistaar/requirements.txt (line 16)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r vistaar/requirements.txt (line 16)) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r vistaar/requirements.txt (line 16)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r vistaar/requirements.txt (line 16)) (1.3.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->-r vistaar/requirements.txt (line 12)) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.41.0.dev0->-r vistaar/requirements.txt (line 7)) (3.1.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa->-r vistaar/requirements.txt (line 12)) (4.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp==2024.4.9->-r vistaar/requirements.txt (line 6)) (3.6)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->-r vistaar/requirements.txt (line 12)) (3.2.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->-r vistaar/requirements.txt (line 12)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r vistaar/requirements.txt (line 16)) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.19.1.dev0->-r vistaar/requirements.txt (line 8)) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed->-r vistaar/requirements.txt (line 17)) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed->-r vistaar/requirements.txt (line 17)) (2.14.6)\nCollecting sphinx>=1.2.0 (from sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinx-7.3.7-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->-r vistaar/requirements.txt (line 10)) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r vistaar/requirements.txt (line 12)) (2.21)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r vistaar/requirements.txt (line 16)) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r vistaar/requirements.txt (line 16)) (3.2.2)\nCollecting sphinxcontrib-applehelp (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-devhelp (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-jsmath (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\nCollecting sphinxcontrib-qthelp (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9)) (2.17.2)\nRequirement already satisfied: docutils<0.22,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9)) (0.21.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9)) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9)) (2.14.0)\nCollecting alabaster~=0.7.14 (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\nCollecting imagesize>=1.3 (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9))\n  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tomli>=2 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library==0.92->-r vistaar/requirements.txt (line 9)) (2.0.1)\nDownloading youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading jiwer-3.0.3-py3-none-any.whl (21 kB)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\nDownloading sphinx-7.3.7-py3-none-any.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\nDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\nDownloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\nDownloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: webrtcvad, yt-dlp, transformers, datasets, indic_nlp_library, deepspeed\n  Building wheel for webrtcvad (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp310-cp310-linux_x86_64.whl size=27295 sha256=416e90f79251a5711a707fddbf71daf2475daec6c397d6e1fa8690f28b7eccd6\n  Stored in directory: /root/.cache/pip/wheels/2a/2b/84/ac7bacfe8c68a87c1ee3dd3c66818a54c71599abf308e8eb35\n  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for yt-dlp: filename=yt_dlp-2024.4.9-py3-none-any.whl size=2828205 sha256=3ca5cf64f47842a15869adc442f6e76096e41439831771a799415ffb1505a9b3\n  Stored in directory: /tmp/pip-ephem-wheel-cache-4q51cn4s/wheels/90/1d/e2/317002f029ce6171f6be15d215f954d19ebeb82ee29477ca11\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.41.0.dev0-py3-none-any.whl size=9043401 sha256=197128941b18d12b4ddf0c7d4aa8baafd0ee7f8aac7ca5957db9b7841eafb5f2\n  Stored in directory: /tmp/pip-ephem-wheel-cache-4q51cn4s/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n  Building wheel for datasets (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for datasets: filename=datasets-2.19.1.dev0-py3-none-any.whl size=515569 sha256=bf6ec616544d609217fb59281ede073d5846b4625b8bb781ca71ea1b504248e0\n  Stored in directory: /tmp/pip-ephem-wheel-cache-4q51cn4s/wheels/7f/ba/ce/8f6a52388a9966c7d9afa987113a763f7c105f568f369adbc6\n  Building wheel for indic_nlp_library (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for indic_nlp_library: filename=indic_nlp_library-0.92-py3-none-any.whl size=40778 sha256=1dd1c57ff3d046472e534bcf059150cda380c2e4bdf571359fa592b88d7310c8\n  Stored in directory: /tmp/pip-ephem-wheel-cache-4q51cn4s/wheels/98/bc/25/381dc5529b731f558b894c7544c4f3ac12ab58b97de9c3b23d\n  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.14.1-py3-none-any.whl size=1421786 sha256=96cac8e1ed01616f25381d34ef2c9284365e7ac4a53ffa85391acdff41899574\n  Stored in directory: /root/.cache/pip/wheels/e6/fc/2e/6b7f04a0a1c7d002edfcf787965c69b90eee5b3aed189d5ffe\nSuccessfully built webrtcvad yt-dlp transformers datasets indic_nlp_library deepspeed\nInstalling collected packages: youtube-dl, webrtcvad, morfessor, hjson, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, rapidfuzz, pycryptodomex, mutagen, imagesize, alabaster, yt-dlp, sphinx, responses, jiwer, tokenizers, sphinx-argparse, deepspeed, transformers, indic_nlp_library, datasets, evaluate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.18.0\n    Uninstalling datasets-2.18.0:\n      Successfully uninstalled datasets-2.18.0\nSuccessfully installed alabaster-0.7.16 datasets-2.19.1.dev0 deepspeed-0.14.1 evaluate-0.4.1 hjson-3.1.0 imagesize-1.4.1 indic_nlp_library-0.92 jiwer-3.0.3 morfessor-2.0.6 mutagen-1.47.0 pycryptodomex-3.20.0 rapidfuzz-3.8.1 responses-0.18.0 sphinx-7.3.7 sphinx-argparse-0.4.0 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10 tokenizers-0.19.1 transformers-4.41.0.dev0 webrtcvad-2.0.10 youtube-dl-2021.6.6 yt-dlp-2024.4.9\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://asr.iitm.ac.in/Gramvaani/NEW/GV_Eval_3h.tar.gz","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:15:06.884321Z","iopub.execute_input":"2024-04-22T22:15:06.884612Z","iopub.status.idle":"2024-04-22T22:15:16.224322Z","shell.execute_reply.started":"2024-04-22T22:15:06.884580Z","shell.execute_reply":"2024-04-22T22:15:16.223400Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"--2024-04-22 22:15:07--  https://asr.iitm.ac.in/Gramvaani/NEW/GV_Eval_3h.tar.gz\nResolving asr.iitm.ac.in (asr.iitm.ac.in)... 103.158.43.117\nConnecting to asr.iitm.ac.in (asr.iitm.ac.in)|103.158.43.117|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 62063203 (59M) [application/x-gzip]\nSaving to: 'GV_Eval_3h.tar.gz'\n\nGV_Eval_3h.tar.gz   100%[===================>]  59.19M  10.9MB/s    in 7.0s    \n\n2024-04-22 22:15:16 (8.45 MB/s) - 'GV_Eval_3h.tar.gz' saved [62063203/62063203]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -xvf GV_Eval_3h.tar.gz","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:15:16.226954Z","iopub.execute_input":"2024-04-22T22:15:16.227777Z","iopub.status.idle":"2024-04-22T22:15:17.824383Z","shell.execute_reply.started":"2024-04-22T22:15:16.227737Z","shell.execute_reply":"2024-04-22T22:15:17.823436Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"GV_Eval_3h/\nGV_Eval_3h/mp3.scp\nGV_Eval_3h/Audio/\nGV_Eval_3h/Audio/01-10385-01.mp3\nGV_Eval_3h/Audio/01-07698-02.mp3\nGV_Eval_3h/Audio/01-10039-03.mp3\nGV_Eval_3h/Audio/01-06541-02.mp3\nGV_Eval_3h/Audio/01-04113-03.mp3\nGV_Eval_3h/Audio/01-06017-03.mp3\nGV_Eval_3h/Audio/01-08119-03.mp3\nGV_Eval_3h/Audio/01-02202-01.mp3\nGV_Eval_3h/Audio/02-12441-02.mp3\nGV_Eval_3h/Audio/02-19554-01.mp3\nGV_Eval_3h/Audio/02-17411-01.mp3\nGV_Eval_3h/Audio/01-02700-01.mp3\nGV_Eval_3h/Audio/01-02028-02.mp3\nGV_Eval_3h/Audio/01-08849-02.mp3\nGV_Eval_3h/Audio/01-10305-01.mp3\nGV_Eval_3h/Audio/02-20406-01.mp3\nGV_Eval_3h/Audio/01-00173-03.mp3\nGV_Eval_3h/Audio/01-09716-01.mp3\nGV_Eval_3h/Audio/02-13097-02.mp3\nGV_Eval_3h/Audio/01-04440-03.mp3\nGV_Eval_3h/Audio/01-06204-03.mp3\nGV_Eval_3h/Audio/02-13282-02.mp3\nGV_Eval_3h/Audio/01-04071-01.mp3\nGV_Eval_3h/Audio/02-15505-01.mp3\nGV_Eval_3h/Audio/01-07839-02.mp3\nGV_Eval_3h/Audio/01-10036-03.mp3\nGV_Eval_3h/Audio/01-07065-03.mp3\nGV_Eval_3h/Audio/02-13426-02.mp3\nGV_Eval_3h/Audio/01-06369-03.mp3\nGV_Eval_3h/Audio/13-00373-04.mp3\nGV_Eval_3h/Audio/01-06450-01.mp3\nGV_Eval_3h/Audio/01-11375-01.mp3\nGV_Eval_3h/Audio/02-18066-01.mp3\nGV_Eval_3h/Audio/01-06730-01.mp3\nGV_Eval_3h/Audio/01-08831-02.mp3\nGV_Eval_3h/Audio/01-06769-02.mp3\nGV_Eval_3h/Audio/02-14654-01.mp3\nGV_Eval_3h/Audio/01-02196-02.mp3\nGV_Eval_3h/Audio/01-01252-02.mp3\nGV_Eval_3h/Audio/02-19999-01.mp3\nGV_Eval_3h/Audio/01-07373-03.mp3\nGV_Eval_3h/Audio/02-16743-01.mp3\nGV_Eval_3h/Audio/01-03791-01.mp3\nGV_Eval_3h/Audio/02-21859-01.mp3\nGV_Eval_3h/Audio/01-01363-02.mp3\nGV_Eval_3h/Audio/02-16176-01.mp3\nGV_Eval_3h/Audio/01-09389-01.mp3\nGV_Eval_3h/Audio/01-08776-01.mp3\nGV_Eval_3h/Audio/13-00245-05.mp3\nGV_Eval_3h/Audio/02-12495-01.mp3\nGV_Eval_3h/Audio/01-07043-02.mp3\nGV_Eval_3h/Audio/01-06967-02.mp3\nGV_Eval_3h/Audio/01-09671-01.mp3\nGV_Eval_3h/Audio/01-02617-03.mp3\nGV_Eval_3h/Audio/01-02425-01.mp3\nGV_Eval_3h/Audio/01-00264-02.mp3\nGV_Eval_3h/Audio/02-14188-01.mp3\nGV_Eval_3h/Audio/01-06524-03.mp3\nGV_Eval_3h/Audio/01-10603-01.mp3\nGV_Eval_3h/Audio/01-08534-01.mp3\nGV_Eval_3h/Audio/01-08598-02.mp3\nGV_Eval_3h/Audio/01-11818-01.mp3\nGV_Eval_3h/Audio/01-06461-03.mp3\nGV_Eval_3h/Audio/01-00004-02.mp3\nGV_Eval_3h/Audio/01-01782-01.mp3\nGV_Eval_3h/Audio/02-17851-01.mp3\nGV_Eval_3h/Audio/01-06081-03.mp3\nGV_Eval_3h/Audio/01-06596-02.mp3\nGV_Eval_3h/Audio/02-20957-01.mp3\nGV_Eval_3h/Audio/02-20174-01.mp3\nGV_Eval_3h/Audio/01-04137-02.mp3\nGV_Eval_3h/Audio/02-17740-01.mp3\nGV_Eval_3h/Audio/01-04332-03.mp3\nGV_Eval_3h/Audio/02-13253-02.mp3\nGV_Eval_3h/Audio/01-10142-01.mp3\nGV_Eval_3h/Audio/02-12608-01.mp3\nGV_Eval_3h/Audio/01-00606-01.mp3\nGV_Eval_3h/Audio/01-07315-02.mp3\nGV_Eval_3h/Audio/01-12042-01.mp3\nGV_Eval_3h/Audio/01-05524-03.mp3\nGV_Eval_3h/Audio/02-13558-01.mp3\nGV_Eval_3h/Audio/01-09682-02.mp3\nGV_Eval_3h/Audio/02-12308-01.mp3\nGV_Eval_3h/Audio/01-11178-03.mp3\nGV_Eval_3h/Audio/01-07199-02.mp3\nGV_Eval_3h/Audio/01-07382-01.mp3\nGV_Eval_3h/Audio/01-05332-03.mp3\nGV_Eval_3h/Audio/01-01903-02.mp3\nGV_Eval_3h/Audio/01-02717-01.mp3\nGV_Eval_3h/Audio/01-08824-01.mp3\nGV_Eval_3h/Audio/01-11375-03.mp3\nGV_Eval_3h/Audio/01-10551-01.mp3\nGV_Eval_3h/Audio/13-00649-03.mp3\nGV_Eval_3h/Audio/01-05318-01.mp3\nGV_Eval_3h/Audio/02-13069-01.mp3\nGV_Eval_3h/Audio/01-11602-02.mp3\nGV_Eval_3h/Audio/01-09311-02.mp3\nGV_Eval_3h/Audio/01-03528-02.mp3\nGV_Eval_3h/Audio/01-08033-03.mp3\nGV_Eval_3h/Audio/02-13377-02.mp3\nGV_Eval_3h/Audio/01-06535-01.mp3\nGV_Eval_3h/Audio/01-10805-03.mp3\nGV_Eval_3h/Audio/01-06875-02.mp3\nGV_Eval_3h/Audio/01-02757-02.mp3\nGV_Eval_3h/Audio/02-13022-02.mp3\nGV_Eval_3h/Audio/01-09841-03.mp3\nGV_Eval_3h/Audio/01-07412-02.mp3\nGV_Eval_3h/Audio/01-04024-02.mp3\nGV_Eval_3h/Audio/01-08224-02.mp3\nGV_Eval_3h/Audio/13-00152-01.mp3\nGV_Eval_3h/Audio/01-10090-03.mp3\nGV_Eval_3h/Audio/01-11569-02.mp3\nGV_Eval_3h/Audio/01-07629-02.mp3\nGV_Eval_3h/Audio/01-10748-01.mp3\nGV_Eval_3h/Audio/01-00990-03.mp3\nGV_Eval_3h/Audio/01-11027-03.mp3\nGV_Eval_3h/Audio/02-12750-02.mp3\nGV_Eval_3h/Audio/01-05247-02.mp3\nGV_Eval_3h/Audio/01-10264-03.mp3\nGV_Eval_3h/Audio/02-18033-01.mp3\nGV_Eval_3h/Audio/01-01992-01.mp3\nGV_Eval_3h/Audio/02-18745-01.mp3\nGV_Eval_3h/Audio/01-00638-03.mp3\nGV_Eval_3h/Audio/01-02735-03.mp3\nGV_Eval_3h/Audio/01-10494-02.mp3\nGV_Eval_3h/Audio/02-19996-01.mp3\nGV_Eval_3h/Audio/01-09098-02.mp3\nGV_Eval_3h/Audio/01-06532-03.mp3\nGV_Eval_3h/Audio/01-05131-03.mp3\nGV_Eval_3h/Audio/01-04428-03.mp3\nGV_Eval_3h/Audio/01-07435-02.mp3\nGV_Eval_3h/Audio/02-19288-01.mp3\nGV_Eval_3h/Audio/02-17099-01.mp3\nGV_Eval_3h/Audio/01-07978-02.mp3\nGV_Eval_3h/Audio/02-16216-01.mp3\nGV_Eval_3h/Audio/02-12706-01.mp3\nGV_Eval_3h/Audio/02-12613-02.mp3\nGV_Eval_3h/Audio/01-03267-01.mp3\nGV_Eval_3h/Audio/02-13573-01.mp3\nGV_Eval_3h/Audio/01-08615-02.mp3\nGV_Eval_3h/Audio/02-18845-01.mp3\nGV_Eval_3h/Audio/01-04216-02.mp3\nGV_Eval_3h/Audio/01-02052-03.mp3\nGV_Eval_3h/Audio/02-13440-01.mp3\nGV_Eval_3h/Audio/01-11972-02.mp3\nGV_Eval_3h/Audio/01-08107-02.mp3\nGV_Eval_3h/Audio/02-21222-01.mp3\nGV_Eval_3h/Audio/02-13660-01.mp3\nGV_Eval_3h/Audio/01-05169-03.mp3\nGV_Eval_3h/Audio/01-03355-01.mp3\nGV_Eval_3h/Audio/02-15188-01.mp3\nGV_Eval_3h/Audio/02-15501-01.mp3\nGV_Eval_3h/Audio/01-01810-01.mp3\nGV_Eval_3h/Audio/01-08832-01.mp3\nGV_Eval_3h/Audio/01-06529-02.mp3\nGV_Eval_3h/Audio/02-15826-01.mp3\nGV_Eval_3h/Audio/02-15302-01.mp3\nGV_Eval_3h/Audio/02-20286-01.mp3\nGV_Eval_3h/Audio/01-11664-01.mp3\nGV_Eval_3h/Audio/01-01458-01.mp3\nGV_Eval_3h/Audio/02-15038-01.mp3\nGV_Eval_3h/Audio/01-08049-03.mp3\nGV_Eval_3h/Audio/01-11769-01.mp3\nGV_Eval_3h/Audio/01-10463-02.mp3\nGV_Eval_3h/Audio/01-03090-02.mp3\nGV_Eval_3h/Audio/13-00670-02.mp3\nGV_Eval_3h/Audio/02-14024-01.mp3\nGV_Eval_3h/Audio/13-00314-01.mp3\nGV_Eval_3h/Audio/02-12963-01.mp3\nGV_Eval_3h/Audio/01-11096-01.mp3\nGV_Eval_3h/Audio/01-10319-01.mp3\nGV_Eval_3h/Audio/01-09262-01.mp3\nGV_Eval_3h/Audio/02-13136-02.mp3\nGV_Eval_3h/Audio/02-18412-01.mp3\nGV_Eval_3h/Audio/01-07646-02.mp3\nGV_Eval_3h/Audio/01-05263-01.mp3\nGV_Eval_3h/Audio/13-00302-03.mp3\nGV_Eval_3h/Audio/01-04877-01.mp3\nGV_Eval_3h/Audio/01-10593-01.mp3\nGV_Eval_3h/Audio/02-17489-01.mp3\nGV_Eval_3h/Audio/13-00471-02.mp3\nGV_Eval_3h/Audio/01-06562-02.mp3\nGV_Eval_3h/Audio/01-03411-01.mp3\nGV_Eval_3h/Audio/01-11693-02.mp3\nGV_Eval_3h/Audio/01-03512-02.mp3\nGV_Eval_3h/Audio/01-02125-02.mp3\nGV_Eval_3h/Audio/01-01884-02.mp3\nGV_Eval_3h/Audio/01-06049-02.mp3\nGV_Eval_3h/Audio/01-04203-01.mp3\nGV_Eval_3h/Audio/02-20058-01.mp3\nGV_Eval_3h/Audio/01-02291-03.mp3\nGV_Eval_3h/Audio/01-02651-02.mp3\nGV_Eval_3h/Audio/01-04121-03.mp3\nGV_Eval_3h/Audio/01-08679-03.mp3\nGV_Eval_3h/Audio/01-05514-03.mp3\nGV_Eval_3h/Audio/02-13527-02.mp3\nGV_Eval_3h/Audio/01-03180-02.mp3\nGV_Eval_3h/Audio/01-07355-02.mp3\nGV_Eval_3h/Audio/02-17569-01.mp3\nGV_Eval_3h/Audio/01-01017-02.mp3\nGV_Eval_3h/Audio/01-10651-02.mp3\nGV_Eval_3h/Audio/01-07868-03.mp3\nGV_Eval_3h/Audio/01-11389-01.mp3\nGV_Eval_3h/Audio/01-10457-02.mp3\nGV_Eval_3h/Audio/01-08935-01.mp3\nGV_Eval_3h/Audio/01-05359-03.mp3\nGV_Eval_3h/Audio/01-01880-03.mp3\nGV_Eval_3h/Audio/01-05231-02.mp3\nGV_Eval_3h/Audio/02-19405-01.mp3\nGV_Eval_3h/Audio/01-02160-01.mp3\nGV_Eval_3h/Audio/01-06236-03.mp3\nGV_Eval_3h/Audio/02-12289-02.mp3\nGV_Eval_3h/Audio/01-04104-03.mp3\nGV_Eval_3h/Audio/01-11453-01.mp3\nGV_Eval_3h/Audio/01-07706-02.mp3\nGV_Eval_3h/Audio/01-08600-03.mp3\nGV_Eval_3h/Audio/01-04868-02.mp3\nGV_Eval_3h/Audio/02-18322-01.mp3\nGV_Eval_3h/Audio/02-22969-01.mp3\nGV_Eval_3h/Audio/01-10232-01.mp3\nGV_Eval_3h/Audio/01-08453-01.mp3\nGV_Eval_3h/Audio/02-12877-02.mp3\nGV_Eval_3h/Audio/01-06101-01.mp3\nGV_Eval_3h/Audio/01-05986-02.mp3\nGV_Eval_3h/Audio/01-04825-02.mp3\nGV_Eval_3h/Audio/01-07513-02.mp3\nGV_Eval_3h/Audio/01-06620-03.mp3\nGV_Eval_3h/Audio/01-00559-01.mp3\nGV_Eval_3h/Audio/01-02781-01.mp3\nGV_Eval_3h/Audio/01-09530-02.mp3\nGV_Eval_3h/Audio/01-05998-01.mp3\nGV_Eval_3h/Audio/01-04169-01.mp3\nGV_Eval_3h/Audio/02-18916-01.mp3\nGV_Eval_3h/Audio/01-09307-02.mp3\nGV_Eval_3h/Audio/02-13443-01.mp3\nGV_Eval_3h/Audio/01-04109-01.mp3\nGV_Eval_3h/Audio/13-00608-02.mp3\nGV_Eval_3h/Audio/01-06997-02.mp3\nGV_Eval_3h/Audio/02-15655-01.mp3\nGV_Eval_3h/Audio/01-03109-03.mp3\nGV_Eval_3h/Audio/01-05852-03.mp3\nGV_Eval_3h/Audio/02-14505-01.mp3\nGV_Eval_3h/Audio/01-04741-02.mp3\nGV_Eval_3h/Audio/01-08875-02.mp3\nGV_Eval_3h/Audio/01-01697-03.mp3\nGV_Eval_3h/Audio/02-17524-01.mp3\nGV_Eval_3h/Audio/02-12573-01.mp3\nGV_Eval_3h/Audio/02-16594-01.mp3\nGV_Eval_3h/Audio/02-16342-01.mp3\nGV_Eval_3h/Audio/02-18860-01.mp3\nGV_Eval_3h/Audio/02-14606-01.mp3\nGV_Eval_3h/Audio/02-19124-01.mp3\nGV_Eval_3h/Audio/01-02334-02.mp3\nGV_Eval_3h/Audio/01-00313-03.mp3\nGV_Eval_3h/Audio/02-17546-01.mp3\nGV_Eval_3h/Audio/02-12935-01.mp3\nGV_Eval_3h/Audio/01-10735-01.mp3\nGV_Eval_3h/Audio/01-10048-03.mp3\nGV_Eval_3h/Audio/02-16943-01.mp3\nGV_Eval_3h/Audio/01-07217-01.mp3\nGV_Eval_3h/Audio/01-06864-02.mp3\nGV_Eval_3h/Audio/01-11494-02.mp3\nGV_Eval_3h/Audio/01-12104-02.mp3\nGV_Eval_3h/Audio/01-06608-03.mp3\nGV_Eval_3h/Audio/01-06294-02.mp3\nGV_Eval_3h/Audio/01-05357-03.mp3\nGV_Eval_3h/Audio/02-12374-01.mp3\nGV_Eval_3h/Audio/02-12299-02.mp3\nGV_Eval_3h/Audio/01-11670-01.mp3\nGV_Eval_3h/Audio/01-01022-03.mp3\nGV_Eval_3h/Audio/01-00755-01.mp3\nGV_Eval_3h/Audio/01-07686-01.mp3\nGV_Eval_3h/Audio/02-13826-01.mp3\nGV_Eval_3h/Audio/13-00232-05.mp3\nGV_Eval_3h/Audio/02-17935-01.mp3\nGV_Eval_3h/Audio/13-00129-04.mp3\nGV_Eval_3h/Audio/01-06926-01.mp3\nGV_Eval_3h/Audio/02-13974-01.mp3\nGV_Eval_3h/Audio/01-07548-01.mp3\nGV_Eval_3h/Audio/01-04703-02.mp3\nGV_Eval_3h/Audio/01-06550-03.mp3\nGV_Eval_3h/Audio/01-01025-03.mp3\nGV_Eval_3h/Audio/02-16526-01.mp3\nGV_Eval_3h/Audio/01-01568-01.mp3\nGV_Eval_3h/Audio/01-11716-01.mp3\nGV_Eval_3h/Audio/01-01423-01.mp3\nGV_Eval_3h/Audio/02-16286-01.mp3\nGV_Eval_3h/Audio/02-16574-01.mp3\nGV_Eval_3h/Audio/02-13897-01.mp3\nGV_Eval_3h/Audio/01-04398-02.mp3\nGV_Eval_3h/Audio/13-00355-03.mp3\nGV_Eval_3h/Audio/02-12425-01.mp3\nGV_Eval_3h/Audio/01-02549-01.mp3\nGV_Eval_3h/Audio/01-11742-01.mp3\nGV_Eval_3h/Audio/01-10107-01.mp3\nGV_Eval_3h/Audio/01-03031-02.mp3\nGV_Eval_3h/Audio/01-05500-03.mp3\nGV_Eval_3h/Audio/01-08248-03.mp3\nGV_Eval_3h/Audio/01-11501-03.mp3\nGV_Eval_3h/Audio/02-16446-01.mp3\nGV_Eval_3h/Audio/01-08656-03.mp3\nGV_Eval_3h/Audio/02-18119-01.mp3\nGV_Eval_3h/Audio/01-04195-02.mp3\nGV_Eval_3h/Audio/02-12802-02.mp3\nGV_Eval_3h/Audio/01-05501-03.mp3\nGV_Eval_3h/Audio/01-05041-01.mp3\nGV_Eval_3h/Audio/01-07096-01.mp3\nGV_Eval_3h/Audio/02-12732-01.mp3\nGV_Eval_3h/Audio/01-06364-01.mp3\nGV_Eval_3h/Audio/01-01639-03.mp3\nGV_Eval_3h/Audio/02-13955-01.mp3\nGV_Eval_3h/Audio/01-03740-01.mp3\nGV_Eval_3h/Audio/02-21091-01.mp3\nGV_Eval_3h/Audio/01-05197-01.mp3\nGV_Eval_3h/Audio/01-05902-02.mp3\nGV_Eval_3h/Audio/01-04281-03.mp3\nGV_Eval_3h/Audio/01-01028-01.mp3\nGV_Eval_3h/Audio/02-12474-02.mp3\nGV_Eval_3h/Audio/01-04132-03.mp3\nGV_Eval_3h/Audio/01-08582-01.mp3\nGV_Eval_3h/Audio/02-18111-01.mp3\nGV_Eval_3h/Audio/01-06296-01.mp3\nGV_Eval_3h/Audio/01-02685-01.mp3\nGV_Eval_3h/Audio/01-03748-01.mp3\nGV_Eval_3h/Audio/01-02956-01.mp3\nGV_Eval_3h/Audio/02-15816-01.mp3\nGV_Eval_3h/Audio/01-08572-03.mp3\nGV_Eval_3h/Audio/01-00129-02.mp3\nGV_Eval_3h/Audio/01-09940-02.mp3\nGV_Eval_3h/Audio/01-11177-02.mp3\nGV_Eval_3h/Audio/01-02179-01.mp3\nGV_Eval_3h/Audio/01-07826-03.mp3\nGV_Eval_3h/Audio/01-08630-03.mp3\nGV_Eval_3h/Audio/01-06650-01.mp3\nGV_Eval_3h/Audio/01-08739-02.mp3\nGV_Eval_3h/Audio/01-11046-03.mp3\nGV_Eval_3h/Audio/01-05567-02.mp3\nGV_Eval_3h/Audio/02-16538-01.mp3\nGV_Eval_3h/Audio/01-04208-01.mp3\nGV_Eval_3h/Audio/01-09796-02.mp3\nGV_Eval_3h/Audio/01-10506-02.mp3\nGV_Eval_3h/Audio/01-05944-02.mp3\nGV_Eval_3h/Audio/13-00238-02.mp3\nGV_Eval_3h/Audio/01-09395-01.mp3\nGV_Eval_3h/Audio/01-06216-02.mp3\nGV_Eval_3h/Audio/01-01226-03.mp3\nGV_Eval_3h/Audio/01-03767-02.mp3\nGV_Eval_3h/Audio/01-10685-03.mp3\nGV_Eval_3h/Audio/01-06401-03.mp3\nGV_Eval_3h/Audio/01-08095-03.mp3\nGV_Eval_3h/Audio/02-21998-01.mp3\nGV_Eval_3h/Audio/01-04318-01.mp3\nGV_Eval_3h/Audio/01-05758-03.mp3\nGV_Eval_3h/Audio/02-18652-01.mp3\nGV_Eval_3h/Audio/02-13728-02.mp3\nGV_Eval_3h/Audio/01-02406-01.mp3\nGV_Eval_3h/Audio/01-00008-03.mp3\nGV_Eval_3h/Audio/01-02135-03.mp3\nGV_Eval_3h/Audio/01-04797-01.mp3\nGV_Eval_3h/Audio/01-04793-02.mp3\nGV_Eval_3h/Audio/01-11388-03.mp3\nGV_Eval_3h/Audio/01-07445-02.mp3\nGV_Eval_3h/Audio/02-18651-01.mp3\nGV_Eval_3h/Audio/01-08602-02.mp3\nGV_Eval_3h/Audio/01-06876-03.mp3\nGV_Eval_3h/Audio/01-03682-02.mp3\nGV_Eval_3h/Audio/01-09229-01.mp3\nGV_Eval_3h/Audio/01-07887-03.mp3\nGV_Eval_3h/Audio/01-07865-01.mp3\nGV_Eval_3h/Audio/13-00315-03.mp3\nGV_Eval_3h/Audio/01-06569-01.mp3\nGV_Eval_3h/Audio/01-11842-02.mp3\nGV_Eval_3h/Audio/01-08416-02.mp3\nGV_Eval_3h/Audio/02-17067-01.mp3\nGV_Eval_3h/Audio/01-08374-03.mp3\nGV_Eval_3h/Audio/01-03989-03.mp3\nGV_Eval_3h/Audio/01-01005-03.mp3\nGV_Eval_3h/Audio/01-08216-02.mp3\nGV_Eval_3h/Audio/01-05945-02.mp3\nGV_Eval_3h/Audio/02-20359-01.mp3\nGV_Eval_3h/Audio/01-09350-01.mp3\nGV_Eval_3h/Audio/01-07957-02.mp3\nGV_Eval_3h/Audio/01-10958-02.mp3\nGV_Eval_3h/Audio/01-05284-03.mp3\nGV_Eval_3h/Audio/01-09295-02.mp3\nGV_Eval_3h/Audio/02-12640-02.mp3\nGV_Eval_3h/Audio/01-01602-01.mp3\nGV_Eval_3h/Audio/01-04493-02.mp3\nGV_Eval_3h/Audio/01-05542-01.mp3\nGV_Eval_3h/Audio/01-10938-03.mp3\nGV_Eval_3h/Audio/01-07396-02.mp3\nGV_Eval_3h/Audio/02-13280-02.mp3\nGV_Eval_3h/Audio/01-09492-02.mp3\nGV_Eval_3h/Audio/01-09868-01.mp3\nGV_Eval_3h/Audio/02-12751-02.mp3\nGV_Eval_3h/Audio/02-15860-01.mp3\nGV_Eval_3h/Audio/02-14905-01.mp3\nGV_Eval_3h/Audio/02-17264-01.mp3\nGV_Eval_3h/Audio/01-12193-01.mp3\nGV_Eval_3h/Audio/01-03881-01.mp3\nGV_Eval_3h/Audio/02-17496-01.mp3\nGV_Eval_3h/Audio/02-20276-01.mp3\nGV_Eval_3h/Audio/01-00869-03.mp3\nGV_Eval_3h/Audio/01-07090-01.mp3\nGV_Eval_3h/Audio/02-19398-01.mp3\nGV_Eval_3h/Audio/13-00367-01.mp3\nGV_Eval_3h/Audio/02-15770-01.mp3\nGV_Eval_3h/Audio/01-01998-03.mp3\nGV_Eval_3h/Audio/02-21365-01.mp3\nGV_Eval_3h/Audio/01-02945-02.mp3\nGV_Eval_3h/Audio/02-13995-01.mp3\nGV_Eval_3h/Audio/01-11496-02.mp3\nGV_Eval_3h/Audio/01-05555-02.mp3\nGV_Eval_3h/Audio/02-14974-01.mp3\nGV_Eval_3h/Audio/02-12609-02.mp3\nGV_Eval_3h/Audio/01-10641-03.mp3\nGV_Eval_3h/Audio/02-18168-01.mp3\nGV_Eval_3h/Audio/01-07455-01.mp3\nGV_Eval_3h/Audio/01-07119-03.mp3\nGV_Eval_3h/Audio/01-07562-01.mp3\nGV_Eval_3h/Audio/01-01042-02.mp3\nGV_Eval_3h/Audio/01-04991-01.mp3\nGV_Eval_3h/Audio/02-12585-01.mp3\nGV_Eval_3h/Audio/01-04925-03.mp3\nGV_Eval_3h/Audio/01-06356-02.mp3\nGV_Eval_3h/Audio/02-12650-01.mp3\nGV_Eval_3h/Audio/02-20288-01.mp3\nGV_Eval_3h/Audio/01-11572-03.mp3\nGV_Eval_3h/Audio/02-16027-01.mp3\nGV_Eval_3h/Audio/01-02080-03.mp3\nGV_Eval_3h/Audio/13-00265-03.mp3\nGV_Eval_3h/Audio/01-05223-01.mp3\nGV_Eval_3h/Audio/01-06254-01.mp3\nGV_Eval_3h/Audio/02-13068-01.mp3\nGV_Eval_3h/Audio/01-00078-01.mp3\nGV_Eval_3h/Audio/01-11537-01.mp3\nGV_Eval_3h/Audio/01-03287-02.mp3\nGV_Eval_3h/Audio/02-13890-01.mp3\nGV_Eval_3h/Audio/02-19520-01.mp3\nGV_Eval_3h/Audio/02-13984-01.mp3\nGV_Eval_3h/Audio/01-10825-02.mp3\nGV_Eval_3h/Audio/02-15402-01.mp3\nGV_Eval_3h/Audio/01-02834-03.mp3\nGV_Eval_3h/Audio/01-02981-02.mp3\nGV_Eval_3h/Audio/13-00553-01.mp3\nGV_Eval_3h/Audio/01-02346-01.mp3\nGV_Eval_3h/Audio/01-11163-03.mp3\nGV_Eval_3h/Audio/02-20803-01.mp3\nGV_Eval_3h/Audio/01-02952-03.mp3\nGV_Eval_3h/Audio/01-08245-03.mp3\nGV_Eval_3h/Audio/02-22310-01.mp3\nGV_Eval_3h/Audio/02-17346-01.mp3\nGV_Eval_3h/Audio/01-00097-03.mp3\nGV_Eval_3h/Audio/01-00262-02.mp3\nGV_Eval_3h/Audio/02-12355-02.mp3\nGV_Eval_3h/Audio/01-03747-03.mp3\nGV_Eval_3h/Audio/01-03144-02.mp3\nGV_Eval_3h/Audio/01-02539-01.mp3\nGV_Eval_3h/Audio/01-07356-02.mp3\nGV_Eval_3h/Audio/01-01558-01.mp3\nGV_Eval_3h/Audio/02-13479-01.mp3\nGV_Eval_3h/Audio/02-15504-01.mp3\nGV_Eval_3h/Audio/13-00277-04.mp3\nGV_Eval_3h/Audio/02-12791-02.mp3\nGV_Eval_3h/Audio/01-04405-03.mp3\nGV_Eval_3h/Audio/01-11500-02.mp3\nGV_Eval_3h/Audio/01-04510-02.mp3\nGV_Eval_3h/Audio/02-14830-01.mp3\nGV_Eval_3h/Audio/02-12290-02.mp3\nGV_Eval_3h/Audio/01-00281-01.mp3\nGV_Eval_3h/Audio/01-07453-01.mp3\nGV_Eval_3h/Audio/13-00417-03.mp3\nGV_Eval_3h/Audio/01-10772-03.mp3\nGV_Eval_3h/Audio/01-03999-01.mp3\nGV_Eval_3h/Audio/01-08420-03.mp3\nGV_Eval_3h/Audio/01-02585-02.mp3\nGV_Eval_3h/Audio/01-04804-03.mp3\nGV_Eval_3h/Audio/01-04756-03.mp3\nGV_Eval_3h/Audio/01-08500-01.mp3\nGV_Eval_3h/Audio/01-11533-01.mp3\nGV_Eval_3h/Audio/01-04454-01.mp3\nGV_Eval_3h/Audio/01-07314-03.mp3\nGV_Eval_3h/Audio/01-02246-02.mp3\nGV_Eval_3h/Audio/13-00089-02.mp3\nGV_Eval_3h/Audio/01-05793-01.mp3\nGV_Eval_3h/Audio/01-02130-02.mp3\nGV_Eval_3h/Audio/01-07252-02.mp3\nGV_Eval_3h/Audio/02-19136-01.mp3\nGV_Eval_3h/Audio/01-05852-01.mp3\nGV_Eval_3h/Audio/02-13236-01.mp3\nGV_Eval_3h/Audio/02-13499-02.mp3\nGV_Eval_3h/Audio/01-01769-02.mp3\nGV_Eval_3h/Audio/01-07821-02.mp3\nGV_Eval_3h/Audio/01-11715-02.mp3\nGV_Eval_3h/Audio/01-06361-01.mp3\nGV_Eval_3h/Audio/01-11618-03.mp3\nGV_Eval_3h/Audio/01-06822-03.mp3\nGV_Eval_3h/Audio/01-02925-01.mp3\nGV_Eval_3h/Audio/01-04320-03.mp3\nGV_Eval_3h/Audio/02-20550-01.mp3\nGV_Eval_3h/Audio/01-02475-02.mp3\nGV_Eval_3h/Audio/01-05431-03.mp3\nGV_Eval_3h/Audio/02-14202-01.mp3\nGV_Eval_3h/Audio/01-11775-01.mp3\nGV_Eval_3h/Audio/01-03128-03.mp3\nGV_Eval_3h/Audio/02-17601-01.mp3\nGV_Eval_3h/Audio/01-04539-01.mp3\nGV_Eval_3h/Audio/02-12467-02.mp3\nGV_Eval_3h/Audio/01-01714-01.mp3\nGV_Eval_3h/Audio/01-02724-03.mp3\nGV_Eval_3h/Audio/02-14362-01.mp3\nGV_Eval_3h/Audio/01-06794-03.mp3\nGV_Eval_3h/Audio/01-08042-01.mp3\nGV_Eval_3h/Audio/02-13583-01.mp3\nGV_Eval_3h/Audio/01-01930-02.mp3\nGV_Eval_3h/Audio/02-13913-01.mp3\nGV_Eval_3h/Audio/13-00150-03.mp3\nGV_Eval_3h/Audio/13-00655-01.mp3\nGV_Eval_3h/Audio/01-02886-02.mp3\nGV_Eval_3h/Audio/01-10667-03.mp3\nGV_Eval_3h/Audio/01-06892-01.mp3\nGV_Eval_3h/Audio/01-01787-01.mp3\nGV_Eval_3h/Audio/02-20297-01.mp3\nGV_Eval_3h/Audio/01-05373-02.mp3\nGV_Eval_3h/Audio/02-16039-01.mp3\nGV_Eval_3h/Audio/02-17733-01.mp3\nGV_Eval_3h/Audio/01-08477-03.mp3\nGV_Eval_3h/Audio/01-05617-03.mp3\nGV_Eval_3h/Audio/02-12733-02.mp3\nGV_Eval_3h/Audio/01-00031-03.mp3\nGV_Eval_3h/Audio/02-16054-01.mp3\nGV_Eval_3h/Audio/02-17081-01.mp3\nGV_Eval_3h/Audio/02-12414-02.mp3\nGV_Eval_3h/Audio/01-09592-02.mp3\nGV_Eval_3h/Audio/01-08276-01.mp3\nGV_Eval_3h/Audio/01-10146-03.mp3\nGV_Eval_3h/Audio/01-07925-02.mp3\nGV_Eval_3h/Audio/01-04953-03.mp3\nGV_Eval_3h/Audio/01-07643-02.mp3\nGV_Eval_3h/Audio/02-19291-01.mp3\nGV_Eval_3h/Audio/01-06564-03.mp3\nGV_Eval_3h/Audio/01-00754-02.mp3\nGV_Eval_3h/Audio/01-08140-01.mp3\nGV_Eval_3h/Audio/02-19130-01.mp3\nGV_Eval_3h/Audio/02-13136-01.mp3\nGV_Eval_3h/Audio/02-12661-01.mp3\nGV_Eval_3h/Audio/13-00135-05.mp3\nGV_Eval_3h/Audio/01-01783-02.mp3\nGV_Eval_3h/Audio/01-08758-03.mp3\nGV_Eval_3h/Audio/02-13378-02.mp3\nGV_Eval_3h/Audio/01-04608-03.mp3\nGV_Eval_3h/Audio/02-15910-01.mp3\nGV_Eval_3h/Audio/01-04154-02.mp3\nGV_Eval_3h/Audio/13-00293-05.mp3\nGV_Eval_3h/Audio/01-03486-01.mp3\nGV_Eval_3h/Audio/01-07907-02.mp3\nGV_Eval_3h/Audio/02-12270-01.mp3\nGV_Eval_3h/Audio/01-06499-02.mp3\nGV_Eval_3h/Audio/01-10135-03.mp3\nGV_Eval_3h/Audio/01-06733-01.mp3\nGV_Eval_3h/Audio/01-06598-03.mp3\nGV_Eval_3h/Audio/01-12073-01.mp3\nGV_Eval_3h/Audio/01-08778-01.mp3\nGV_Eval_3h/Audio/01-03553-02.mp3\nGV_Eval_3h/Audio/02-17573-01.mp3\nGV_Eval_3h/Audio/01-05967-03.mp3\nGV_Eval_3h/Audio/01-00144-03.mp3\nGV_Eval_3h/Audio/01-09554-02.mp3\nGV_Eval_3h/Audio/01-04571-02.mp3\nGV_Eval_3h/Audio/01-02017-03.mp3\nGV_Eval_3h/Audio/01-09125-02.mp3\nGV_Eval_3h/Audio/01-10211-03.mp3\nGV_Eval_3h/Audio/01-01817-02.mp3\nGV_Eval_3h/Audio/02-15045-01.mp3\nGV_Eval_3h/Audio/01-04324-03.mp3\nGV_Eval_3h/Audio/02-19045-01.mp3\nGV_Eval_3h/Audio/02-22546-01.mp3\nGV_Eval_3h/Audio/01-03501-01.mp3\nGV_Eval_3h/Audio/01-03289-03.mp3\nGV_Eval_3h/Audio/02-18751-01.mp3\nGV_Eval_3h/Audio/01-04575-03.mp3\nGV_Eval_3h/Audio/01-10844-02.mp3\nGV_Eval_3h/Audio/01-10820-02.mp3\nGV_Eval_3h/Audio/01-10250-01.mp3\nGV_Eval_3h/Audio/01-07475-01.mp3\nGV_Eval_3h/Audio/01-10115-02.mp3\nGV_Eval_3h/Audio/01-01599-03.mp3\nGV_Eval_3h/Audio/01-11190-02.mp3\nGV_Eval_3h/Audio/01-08718-02.mp3\nGV_Eval_3h/Audio/01-10642-01.mp3\nGV_Eval_3h/Audio/13-00293-06.mp3\nGV_Eval_3h/Audio/02-16304-01.mp3\nGV_Eval_3h/Audio/01-07423-01.mp3\nGV_Eval_3h/Audio/01-07312-01.mp3\nGV_Eval_3h/Audio/01-03035-03.mp3\nGV_Eval_3h/Audio/01-04700-03.mp3\nGV_Eval_3h/Audio/02-22322-01.mp3\nGV_Eval_3h/Audio/01-01227-01.mp3\nGV_Eval_3h/Audio/01-10333-01.mp3\nGV_Eval_3h/Audio/02-17467-01.mp3\nGV_Eval_3h/Audio/01-06591-02.mp3\nGV_Eval_3h/Audio/01-07331-02.mp3\nGV_Eval_3h/Audio/01-06307-01.mp3\nGV_Eval_3h/Audio/01-09976-02.mp3\nGV_Eval_3h/Audio/01-09398-01.mp3\nGV_Eval_3h/Audio/01-06911-03.mp3\nGV_Eval_3h/Audio/01-12107-01.mp3\nGV_Eval_3h/Audio/01-00071-02.mp3\nGV_Eval_3h/Audio/01-07342-02.mp3\nGV_Eval_3h/Audio/01-10299-01.mp3\nGV_Eval_3h/Audio/01-12218-01.mp3\nGV_Eval_3h/Audio/01-08400-01.mp3\nGV_Eval_3h/Audio/01-05003-02.mp3\nGV_Eval_3h/Audio/01-11424-02.mp3\nGV_Eval_3h/Audio/01-03179-03.mp3\nGV_Eval_3h/Audio/01-04084-02.mp3\nGV_Eval_3h/Audio/01-08572-02.mp3\nGV_Eval_3h/Audio/01-03753-01.mp3\nGV_Eval_3h/Audio/02-13646-02.mp3\nGV_Eval_3h/Audio/02-20927-01.mp3\nGV_Eval_3h/Audio/02-12534-02.mp3\nGV_Eval_3h/Audio/01-00900-02.mp3\nGV_Eval_3h/Audio/02-13701-02.mp3\nGV_Eval_3h/Audio/01-05888-01.mp3\nGV_Eval_3h/Audio/02-22739-01.mp3\nGV_Eval_3h/Audio/01-10827-03.mp3\nGV_Eval_3h/Audio/01-10003-03.mp3\nGV_Eval_3h/Audio/01-09833-03.mp3\nGV_Eval_3h/Audio/02-13692-02.mp3\nGV_Eval_3h/Audio/01-10424-03.mp3\nGV_Eval_3h/Audio/01-02979-01.mp3\nGV_Eval_3h/Audio/01-11659-03.mp3\nGV_Eval_3h/Audio/01-02225-01.mp3\nGV_Eval_3h/Audio/01-10237-02.mp3\nGV_Eval_3h/Audio/01-08722-03.mp3\nGV_Eval_3h/Audio/01-00622-03.mp3\nGV_Eval_3h/Audio/01-03176-02.mp3\nGV_Eval_3h/Audio/01-08962-02.mp3\nGV_Eval_3h/Audio/02-21292-01.mp3\nGV_Eval_3h/Audio/02-17266-01.mp3\nGV_Eval_3h/Audio/01-00131-03.mp3\nGV_Eval_3h/Audio/01-03685-02.mp3\nGV_Eval_3h/Audio/01-06019-03.mp3\nGV_Eval_3h/Audio/01-07691-01.mp3\nGV_Eval_3h/Audio/01-11403-02.mp3\nGV_Eval_3h/Audio/01-10976-03.mp3\nGV_Eval_3h/Audio/02-15237-01.mp3\nGV_Eval_3h/Audio/02-12240-02.mp3\nGV_Eval_3h/Audio/02-16015-01.mp3\nGV_Eval_3h/Audio/01-06499-01.mp3\nGV_Eval_3h/Audio/01-02163-02.mp3\nGV_Eval_3h/Audio/02-13513-01.mp3\nGV_Eval_3h/Audio/02-19271-01.mp3\nGV_Eval_3h/Audio/13-00272-06.mp3\nGV_Eval_3h/Audio/02-14351-01.mp3\nGV_Eval_3h/Audio/02-17207-01.mp3\nGV_Eval_3h/Audio/01-01074-02.mp3\nGV_Eval_3h/Audio/02-13734-02.mp3\nGV_Eval_3h/Audio/01-05651-01.mp3\nGV_Eval_3h/Audio/01-01557-01.mp3\nGV_Eval_3h/Audio/02-19886-01.mp3\nGV_Eval_3h/Audio/02-19443-01.mp3\nGV_Eval_3h/Audio/02-20013-01.mp3\nGV_Eval_3h/Audio/02-14222-01.mp3\nGV_Eval_3h/Audio/01-06134-02.mp3\nGV_Eval_3h/Audio/02-12399-02.mp3\nGV_Eval_3h/Audio/01-00616-03.mp3\nGV_Eval_3h/Audio/01-05158-01.mp3\nGV_Eval_3h/Audio/02-13972-01.mp3\nGV_Eval_3h/Audio/13-00426-01.mp3\nGV_Eval_3h/Audio/01-09956-02.mp3\nGV_Eval_3h/Audio/01-10103-03.mp3\nGV_Eval_3h/Audio/01-10120-03.mp3\nGV_Eval_3h/Audio/01-10747-03.mp3\nGV_Eval_3h/Audio/01-07594-02.mp3\nGV_Eval_3h/Audio/01-12225-02.mp3\nGV_Eval_3h/Audio/01-08600-01.mp3\nGV_Eval_3h/Audio/02-13075-02.mp3\nGV_Eval_3h/Audio/01-00321-01.mp3\nGV_Eval_3h/Audio/01-10029-02.mp3\nGV_Eval_3h/Audio/01-05094-02.mp3\nGV_Eval_3h/Audio/01-06986-01.mp3\nGV_Eval_3h/Audio/01-08407-02.mp3\nGV_Eval_3h/Audio/01-08930-02.mp3\nGV_Eval_3h/Audio/02-20293-01.mp3\nGV_Eval_3h/Audio/02-17148-01.mp3\nGV_Eval_3h/Audio/01-05579-01.mp3\nGV_Eval_3h/Audio/01-10402-03.mp3\nGV_Eval_3h/Audio/01-05071-03.mp3\nGV_Eval_3h/Audio/01-00159-01.mp3\nGV_Eval_3h/Audio/02-18937-01.mp3\nGV_Eval_3h/Audio/01-09847-01.mp3\nGV_Eval_3h/Audio/01-04514-02.mp3\nGV_Eval_3h/Audio/01-08310-03.mp3\nGV_Eval_3h/Audio/01-00768-01.mp3\nGV_Eval_3h/Audio/01-06591-03.mp3\nGV_Eval_3h/Audio/02-18403-01.mp3\nGV_Eval_3h/Audio/02-20467-01.mp3\nGV_Eval_3h/Audio/02-20583-01.mp3\nGV_Eval_3h/Audio/02-22641-01.mp3\nGV_Eval_3h/Audio/01-00960-03.mp3\nGV_Eval_3h/Audio/02-19680-01.mp3\nGV_Eval_3h/Audio/01-09491-02.mp3\nGV_Eval_3h/Audio/02-12419-02.mp3\nGV_Eval_3h/Audio/01-01217-02.mp3\nGV_Eval_3h/Audio/01-10436-03.mp3\nGV_Eval_3h/Audio/01-10739-01.mp3\nGV_Eval_3h/Audio/01-01235-03.mp3\nGV_Eval_3h/Audio/02-18435-01.mp3\nGV_Eval_3h/Audio/01-00871-02.mp3\nGV_Eval_3h/Audio/01-10852-03.mp3\nGV_Eval_3h/Audio/01-01029-02.mp3\nGV_Eval_3h/Audio/13-00368-04.mp3\nGV_Eval_3h/Audio/01-10891-03.mp3\nGV_Eval_3h/Audio/01-00804-03.mp3\nGV_Eval_3h/Audio/02-15827-01.mp3\nGV_Eval_3h/Audio/01-03277-03.mp3\nGV_Eval_3h/Audio/01-03411-03.mp3\nGV_Eval_3h/Audio/01-07995-03.mp3\nGV_Eval_3h/Audio/01-00946-01.mp3\nGV_Eval_3h/Audio/02-15146-01.mp3\nGV_Eval_3h/Audio/01-12224-01.mp3\nGV_Eval_3h/Audio/01-11573-03.mp3\nGV_Eval_3h/Audio/02-18450-01.mp3\nGV_Eval_3h/Audio/02-13373-01.mp3\nGV_Eval_3h/Audio/01-08821-02.mp3\nGV_Eval_3h/Audio/01-03076-02.mp3\nGV_Eval_3h/Audio/01-02482-01.mp3\nGV_Eval_3h/Audio/01-02855-03.mp3\nGV_Eval_3h/Audio/02-13634-02.mp3\nGV_Eval_3h/Audio/01-10431-01.mp3\nGV_Eval_3h/Audio/01-00685-03.mp3\nGV_Eval_3h/Audio/01-12002-02.mp3\nGV_Eval_3h/Audio/02-22743-01.mp3\nGV_Eval_3h/Audio/02-21135-01.mp3\nGV_Eval_3h/Audio/01-01670-02.mp3\nGV_Eval_3h/Audio/02-14371-01.mp3\nGV_Eval_3h/Audio/01-08678-01.mp3\nGV_Eval_3h/Audio/02-12536-02.mp3\nGV_Eval_3h/Audio/01-01738-02.mp3\nGV_Eval_3h/Audio/01-06719-02.mp3\nGV_Eval_3h/Audio/01-04927-02.mp3\nGV_Eval_3h/Audio/01-06170-02.mp3\nGV_Eval_3h/Audio/02-12916-02.mp3\nGV_Eval_3h/Audio/01-07183-02.mp3\nGV_Eval_3h/Audio/01-04407-01.mp3\nGV_Eval_3h/Audio/01-00703-03.mp3\nGV_Eval_3h/Audio/13-00155-06.mp3\nGV_Eval_3h/Audio/01-05071-01.mp3\nGV_Eval_3h/Audio/01-08630-01.mp3\nGV_Eval_3h/Audio/01-07450-02.mp3\nGV_Eval_3h/Audio/02-12881-01.mp3\nGV_Eval_3h/Audio/02-15404-01.mp3\nGV_Eval_3h/Audio/01-11351-03.mp3\nGV_Eval_3h/Audio/01-10001-02.mp3\nGV_Eval_3h/Audio/01-11183-02.mp3\nGV_Eval_3h/Audio/02-18353-01.mp3\nGV_Eval_3h/Audio/01-05917-02.mp3\nGV_Eval_3h/Audio/01-09487-01.mp3\nGV_Eval_3h/Audio/01-02007-03.mp3\nGV_Eval_3h/Audio/01-10198-03.mp3\nGV_Eval_3h/Audio/01-12128-02.mp3\nGV_Eval_3h/Audio/02-21579-01.mp3\nGV_Eval_3h/Audio/01-07163-01.mp3\nGV_Eval_3h/Audio/01-03829-03.mp3\nGV_Eval_3h/Audio/01-10863-01.mp3\nGV_Eval_3h/Audio/02-21289-01.mp3\nGV_Eval_3h/Audio/02-14175-01.mp3\nGV_Eval_3h/Audio/01-11373-03.mp3\nGV_Eval_3h/Audio/13-00631-03.mp3\nGV_Eval_3h/Audio/02-12566-02.mp3\nGV_Eval_3h/Audio/01-06445-01.mp3\nGV_Eval_3h/Audio/01-07825-03.mp3\nGV_Eval_3h/Audio/01-08414-01.mp3\nGV_Eval_3h/Audio/02-12354-02.mp3\nGV_Eval_3h/Audio/01-00305-02.mp3\nGV_Eval_3h/Audio/01-03519-03.mp3\nGV_Eval_3h/Audio/02-16569-01.mp3\nGV_Eval_3h/Audio/01-11616-01.mp3\nGV_Eval_3h/Audio/01-07432-03.mp3\nGV_Eval_3h/Audio/02-13559-01.mp3\nGV_Eval_3h/Audio/01-11134-02.mp3\nGV_Eval_3h/Audio/01-07205-01.mp3\nGV_Eval_3h/Audio/02-21359-01.mp3\nGV_Eval_3h/Audio/13-00315-05.mp3\nGV_Eval_3h/Audio/02-16925-01.mp3\nGV_Eval_3h/Audio/01-02106-02.mp3\nGV_Eval_3h/Audio/01-01287-02.mp3\nGV_Eval_3h/Audio/01-07667-02.mp3\nGV_Eval_3h/Audio/02-13887-01.mp3\nGV_Eval_3h/Audio/01-05430-01.mp3\nGV_Eval_3h/Audio/01-09699-02.mp3\nGV_Eval_3h/Audio/01-00159-02.mp3\nGV_Eval_3h/Audio/01-10537-03.mp3\nGV_Eval_3h/Audio/01-04808-01.mp3\nGV_Eval_3h/Audio/01-11079-01.mp3\nGV_Eval_3h/Audio/01-00760-03.mp3\nGV_Eval_3h/Audio/01-08274-02.mp3\nGV_Eval_3h/Audio/01-10519-01.mp3\nGV_Eval_3h/Audio/01-09945-03.mp3\nGV_Eval_3h/Audio/01-00142-01.mp3\nGV_Eval_3h/Audio/01-08268-02.mp3\nGV_Eval_3h/Audio/01-03378-02.mp3\nGV_Eval_3h/Audio/02-16847-01.mp3\nGV_Eval_3h/Audio/01-03209-03.mp3\nGV_Eval_3h/Audio/02-12258-02.mp3\nGV_Eval_3h/Audio/02-13769-02.mp3\nGV_Eval_3h/Audio/01-03501-02.mp3\nGV_Eval_3h/Audio/02-20046-01.mp3\nGV_Eval_3h/Audio/01-10982-01.mp3\nGV_Eval_3h/Audio/01-04574-03.mp3\nGV_Eval_3h/Audio/01-09357-02.mp3\nGV_Eval_3h/Audio/01-12161-02.mp3\nGV_Eval_3h/Audio/01-08969-01.mp3\nGV_Eval_3h/Audio/02-14283-01.mp3\nGV_Eval_3h/Audio/01-03944-02.mp3\nGV_Eval_3h/Audio/01-01826-03.mp3\nGV_Eval_3h/Audio/01-07303-01.mp3\nGV_Eval_3h/Audio/01-01583-01.mp3\nGV_Eval_3h/Audio/02-19008-01.mp3\nGV_Eval_3h/Audio/02-18079-01.mp3\nGV_Eval_3h/Audio/02-18589-01.mp3\nGV_Eval_3h/Audio/01-05290-03.mp3\nGV_Eval_3h/Audio/02-18650-01.mp3\nGV_Eval_3h/Audio/02-19101-01.mp3\nGV_Eval_3h/Audio/01-01696-02.mp3\nGV_Eval_3h/Audio/02-14154-01.mp3\nGV_Eval_3h/Audio/02-13257-01.mp3\nGV_Eval_3h/Audio/01-11195-01.mp3\nGV_Eval_3h/Audio/01-04465-03.mp3\nGV_Eval_3h/Audio/02-21973-01.mp3\nGV_Eval_3h/Audio/01-08217-02.mp3\nGV_Eval_3h/Audio/01-05699-02.mp3\nGV_Eval_3h/Audio/01-06120-02.mp3\nGV_Eval_3h/Audio/01-01556-01.mp3\nGV_Eval_3h/Audio/01-10805-01.mp3\nGV_Eval_3h/Audio/01-04510-03.mp3\nGV_Eval_3h/Audio/01-06866-03.mp3\nGV_Eval_3h/Audio/02-20500-01.mp3\nGV_Eval_3h/Audio/01-11188-02.mp3\nGV_Eval_3h/Audio/02-15015-01.mp3\nGV_Eval_3h/Audio/02-12587-02.mp3\nGV_Eval_3h/Audio/01-02324-01.mp3\nGV_Eval_3h/Audio/02-19301-01.mp3\nGV_Eval_3h/Audio/01-00666-01.mp3\nGV_Eval_3h/Audio/01-03535-01.mp3\nGV_Eval_3h/Audio/01-11441-03.mp3\nGV_Eval_3h/Audio/02-18252-01.mp3\nGV_Eval_3h/Audio/01-09144-01.mp3\nGV_Eval_3h/Audio/01-07662-03.mp3\nGV_Eval_3h/Audio/01-04031-02.mp3\nGV_Eval_3h/Audio/01-08680-03.mp3\nGV_Eval_3h/Audio/13-00286-04.mp3\nGV_Eval_3h/Audio/02-15013-01.mp3\nGV_Eval_3h/Audio/01-07484-01.mp3\nGV_Eval_3h/Audio/01-04929-01.mp3\nGV_Eval_3h/Audio/01-08538-01.mp3\nGV_Eval_3h/Audio/01-11502-03.mp3\nGV_Eval_3h/Audio/02-12479-02.mp3\nGV_Eval_3h/Audio/13-00159-01.mp3\nGV_Eval_3h/Audio/01-12047-02.mp3\nGV_Eval_3h/Audio/02-16277-01.mp3\nGV_Eval_3h/Audio/02-12720-01.mp3\nGV_Eval_3h/Audio/01-03448-02.mp3\nGV_Eval_3h/Audio/01-00093-01.mp3\nGV_Eval_3h/Audio/01-06852-03.mp3\nGV_Eval_3h/Audio/01-04225-02.mp3\nGV_Eval_3h/Audio/01-04690-02.mp3\nGV_Eval_3h/Audio/02-18071-01.mp3\nGV_Eval_3h/Audio/02-21179-01.mp3\nGV_Eval_3h/Audio/01-10801-02.mp3\nGV_Eval_3h/Audio/01-05117-01.mp3\nGV_Eval_3h/Audio/01-02099-01.mp3\nGV_Eval_3h/Audio/01-01534-01.mp3\nGV_Eval_3h/Audio/01-10914-03.mp3\nGV_Eval_3h/Audio/01-10262-03.mp3\nGV_Eval_3h/Audio/01-07823-03.mp3\nGV_Eval_3h/Audio/01-08754-01.mp3\nGV_Eval_3h/Audio/01-11691-01.mp3\nGV_Eval_3h/Audio/01-11030-01.mp3\nGV_Eval_3h/Audio/01-04397-02.mp3\nGV_Eval_3h/Audio/02-18014-01.mp3\nGV_Eval_3h/Audio/02-17400-01.mp3\nGV_Eval_3h/Audio/02-20177-01.mp3\nGV_Eval_3h/Audio/01-02607-03.mp3\nGV_Eval_3h/Audio/01-11550-03.mp3\nGV_Eval_3h/Audio/01-08036-02.mp3\nGV_Eval_3h/Audio/02-12778-01.mp3\nGV_Eval_3h/Audio/02-15876-01.mp3\nGV_Eval_3h/Audio/01-10009-02.mp3\nGV_Eval_3h/Audio/02-19567-01.mp3\nGV_Eval_3h/Audio/02-12779-01.mp3\nGV_Eval_3h/Audio/02-20481-01.mp3\nGV_Eval_3h/Audio/02-15342-01.mp3\nGV_Eval_3h/Audio/01-07059-01.mp3\nGV_Eval_3h/Audio/01-09545-02.mp3\nGV_Eval_3h/Audio/01-08139-03.mp3\nGV_Eval_3h/Audio/02-13866-01.mp3\nGV_Eval_3h/Audio/01-08132-03.mp3\nGV_Eval_3h/Audio/01-00576-01.mp3\nGV_Eval_3h/Audio/02-14428-01.mp3\nGV_Eval_3h/Audio/02-14755-01.mp3\nGV_Eval_3h/Audio/01-04827-03.mp3\nGV_Eval_3h/Audio/01-03048-01.mp3\nGV_Eval_3h/Audio/01-01003-01.mp3\nGV_Eval_3h/Audio/02-22834-01.mp3\nGV_Eval_3h/Audio/01-00352-03.mp3\nGV_Eval_3h/Audio/01-10416-01.mp3\nGV_Eval_3h/Audio/01-02960-03.mp3\nGV_Eval_3h/Audio/01-06755-01.mp3\nGV_Eval_3h/Audio/01-06734-01.mp3\nGV_Eval_3h/Audio/01-02287-01.mp3\nGV_Eval_3h/Audio/02-12618-02.mp3\nGV_Eval_3h/Audio/01-03304-01.mp3\nGV_Eval_3h/Audio/01-06127-03.mp3\nGV_Eval_3h/Audio/01-12018-02.mp3\nGV_Eval_3h/Audio/02-19168-01.mp3\nGV_Eval_3h/Audio/01-10480-03.mp3\nGV_Eval_3h/Audio/01-04714-02.mp3\nGV_Eval_3h/Audio/01-04095-02.mp3\nGV_Eval_3h/Audio/01-03347-03.mp3\nGV_Eval_3h/Audio/01-04975-02.mp3\nGV_Eval_3h/Audio/01-09100-01.mp3\nGV_Eval_3h/Audio/02-16903-01.mp3\nGV_Eval_3h/Audio/01-10083-01.mp3\nGV_Eval_3h/Audio/01-07092-02.mp3\nGV_Eval_3h/Audio/01-09863-03.mp3\nGV_Eval_3h/Audio/01-01922-03.mp3\nGV_Eval_3h/Audio/01-00759-03.mp3\nGV_Eval_3h/Audio/01-02492-02.mp3\nGV_Eval_3h/Audio/02-12449-02.mp3\nGV_Eval_3h/Audio/01-02946-01.mp3\nGV_Eval_3h/Audio/01-08017-03.mp3\nGV_Eval_3h/Audio/01-07184-02.mp3\nGV_Eval_3h/Audio/01-05972-01.mp3\nGV_Eval_3h/Audio/01-09286-02.mp3\nGV_Eval_3h/Audio/02-12848-02.mp3\nGV_Eval_3h/Audio/02-13572-01.mp3\nGV_Eval_3h/Audio/02-12363-02.mp3\nGV_Eval_3h/Audio/01-02139-03.mp3\nGV_Eval_3h/Audio/01-10037-03.mp3\nGV_Eval_3h/Audio/01-01255-01.mp3\nGV_Eval_3h/Audio/01-06565-03.mp3\nGV_Eval_3h/Audio/02-18854-01.mp3\nGV_Eval_3h/Audio/01-09278-01.mp3\nGV_Eval_3h/Audio/01-06421-03.mp3\nGV_Eval_3h/Audio/01-05178-03.mp3\nGV_Eval_3h/Audio/01-00639-03.mp3\nGV_Eval_3h/Audio/01-08352-02.mp3\nGV_Eval_3h/Audio/01-08047-01.mp3\nGV_Eval_3h/Audio/13-00265-02.mp3\nGV_Eval_3h/Audio/01-11055-03.mp3\nGV_Eval_3h/Audio/02-12641-02.mp3\nGV_Eval_3h/Audio/01-08134-02.mp3\nGV_Eval_3h/Audio/01-02217-01.mp3\nGV_Eval_3h/Audio/01-08046-01.mp3\nGV_Eval_3h/Audio/02-12926-02.mp3\nGV_Eval_3h/Audio/01-00802-01.mp3\nGV_Eval_3h/Audio/01-06328-01.mp3\nGV_Eval_3h/Audio/02-13557-02.mp3\nGV_Eval_3h/Audio/02-13130-02.mp3\nGV_Eval_3h/Audio/01-05842-01.mp3\nGV_Eval_3h/Audio/01-07649-03.mp3\nGV_Eval_3h/Audio/01-07986-01.mp3\nGV_Eval_3h/Audio/02-19814-01.mp3\nGV_Eval_3h/Audio/01-06084-03.mp3\nGV_Eval_3h/Audio/02-16456-01.mp3\nGV_Eval_3h/Audio/01-08232-01.mp3\nGV_Eval_3h/Audio/02-22228-01.mp3\nGV_Eval_3h/Audio/01-01990-01.mp3\nGV_Eval_3h/Audio/02-18570-01.mp3\nGV_Eval_3h/Audio/01-03050-02.mp3\nGV_Eval_3h/Audio/02-13147-01.mp3\nGV_Eval_3h/Audio/01-03123-03.mp3\nGV_Eval_3h/Audio/01-04975-03.mp3\nGV_Eval_3h/Audio/02-15830-01.mp3\nGV_Eval_3h/Audio/01-04780-01.mp3\nGV_Eval_3h/Audio/01-03465-02.mp3\nGV_Eval_3h/Audio/02-19533-01.mp3\nGV_Eval_3h/Audio/01-08015-03.mp3\nGV_Eval_3h/Audio/02-14246-01.mp3\nGV_Eval_3h/Audio/01-10510-02.mp3\nGV_Eval_3h/Audio/02-19791-01.mp3\nGV_Eval_3h/Audio/01-04050-03.mp3\nGV_Eval_3h/Audio/01-11943-02.mp3\nGV_Eval_3h/Audio/01-01568-03.mp3\nGV_Eval_3h/Audio/02-21465-01.mp3\nGV_Eval_3h/Audio/01-00119-02.mp3\nGV_Eval_3h/Audio/01-02751-01.mp3\nGV_Eval_3h/Audio/01-10095-03.mp3\nGV_Eval_3h/Audio/01-07814-03.mp3\nGV_Eval_3h/Audio/02-15686-01.mp3\nGV_Eval_3h/Audio/01-00984-01.mp3\nGV_Eval_3h/Audio/01-11009-02.mp3\nGV_Eval_3h/Audio/01-09311-01.mp3\nGV_Eval_3h/Audio/01-06706-01.mp3\nGV_Eval_3h/Audio/02-16919-01.mp3\nGV_Eval_3h/Audio/02-16610-01.mp3\nGV_Eval_3h/Audio/01-07607-02.mp3\nGV_Eval_3h/Audio/02-12256-01.mp3\nGV_Eval_3h/Audio/01-00121-02.mp3\nGV_Eval_3h/Audio/01-02783-03.mp3\nGV_Eval_3h/Audio/01-02279-03.mp3\nGV_Eval_3h/Audio/01-06865-02.mp3\nGV_Eval_3h/Audio/02-12667-02.mp3\nGV_Eval_3h/Audio/02-16097-01.mp3\nGV_Eval_3h/Audio/01-05076-01.mp3\nGV_Eval_3h/Audio/01-08886-03.mp3\nGV_Eval_3h/Audio/02-17956-01.mp3\nGV_Eval_3h/Audio/01-01715-03.mp3\nGV_Eval_3h/Audio/01-04468-02.mp3\nGV_Eval_3h/Audio/02-19238-01.mp3\nGV_Eval_3h/Audio/02-14137-01.mp3\nGV_Eval_3h/Audio/02-18769-01.mp3\nGV_Eval_3h/Audio/01-04673-03.mp3\nGV_Eval_3h/Audio/01-07464-01.mp3\nGV_Eval_3h/Audio/01-11706-02.mp3\nGV_Eval_3h/Audio/02-16251-01.mp3\nGV_Eval_3h/Audio/01-03589-02.mp3\nGV_Eval_3h/Audio/01-06169-02.mp3\nGV_Eval_3h/Audio/01-07535-03.mp3\nGV_Eval_3h/Audio/01-02424-01.mp3\nGV_Eval_3h/Audio/01-02182-02.mp3\nGV_Eval_3h/Audio/01-08638-03.mp3\nGV_Eval_3h/Audio/02-13827-01.mp3\nGV_Eval_3h/Audio/01-05821-02.mp3\nGV_Eval_3h/Audio/01-03018-03.mp3\nGV_Eval_3h/Audio/01-08651-02.mp3\nGV_Eval_3h/Audio/01-08599-02.mp3\nGV_Eval_3h/Audio/01-07059-03.mp3\nGV_Eval_3h/Audio/01-07665-01.mp3\nGV_Eval_3h/Audio/01-04411-03.mp3\nGV_Eval_3h/uttids\nGV_Eval_3h/text\nGV_Eval_3h/utt2labels\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pydub","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:15:17.825860Z","iopub.execute_input":"2024-04-22T22:15:17.826216Z","iopub.status.idle":"2024-04-22T22:15:30.701304Z","shell.execute_reply.started":"2024-04-22T22:15:17.826187Z","shell.execute_reply":"2024-04-22T22:15:30.700217Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from pydub import AudioSegment\nimport os\n\n# Path to the folder containing the audio files\naudio_folder = \"GV_Eval_3h/Audio\"\n# Path to the folder where you want to save the WAV files\noutput_folder = \"audiowav\"\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Iterate over all audio files in the input folder\nfor filename in os.listdir(audio_folder):\n    if filename.endswith(\".mp3\"):  # Assuming all files are in MP3 format\n        # Load the audio file\n        audio = AudioSegment.from_file(os.path.join(audio_folder, filename))\n        # Set the output file name\n        output_filename = os.path.splitext(filename)[0] + \".wav\"\n        # Export the audio file as WAV\n        audio.export(os.path.join(output_folder, output_filename), format=\"wav\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:05:12.507373Z","iopub.execute_input":"2024-04-22T23:05:12.507738Z","iopub.status.idle":"2024-04-22T23:07:45.657199Z","shell.execute_reply.started":"2024-04-22T23:05:12.507707Z","shell.execute_reply":"2024-04-22T23:07:45.656174Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline\n\n# path to the audio file to be transcribed\naudio = \"/kaggle/working/audiowav/01-00321-01.wav\"\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\ntranscribe = pipeline(task=\"automatic-speech-recognition\", model=\"vasista22/whisper-hindi-small\", chunk_length_s=30, device=device)\ntranscribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n\nprint('Transcription: ', transcribe(audio)[\"text\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:20:57.964489Z","iopub.execute_input":"2024-04-22T22:20:57.965332Z","iopub.status.idle":"2024-04-22T22:21:28.521947Z","shell.execute_reply.started":"2024-04-22T22:20:57.965298Z","shell.execute_reply":"2024-04-22T22:21:28.520758Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-04-22 22:21:02.333748: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-22 22:21:02.333865: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-22 22:21:02.497597: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a728619e9084ca9bcbf0f6a07b89711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b54232665f14feeb9dd05196a4280ee"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"532ab45aea534c428c919cc903c0be07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245091ff0626488f9a6e76c1991af590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"828a3283141f42c3a2051c5a0a73505f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b9c331f7da4c809d3ba68dbaacb77c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ef168d84434ec983e2cec9a4502d01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23eb863b28784620a0204c8f2ee56405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e706110863b14ed19f891b429f016c50"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dbfc305d1774c66a16475a5418cf03d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Transcription:  खंडवानी के माध्यम ऐसी इसके लिए मैं खंडवानी को कोटी कोटी नमन करता हूँ और आशा करता हूँ की\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline\n\n# Path to the audio file to be transcribed\naudio = \"/kaggle/working/audiowav/01-00321-01.wav\"\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Create an ASR pipeline\ntranscribe = pipeline(task=\"automatic-speech-recognition\", model=\"vasista22/whisper-hindi-small\", chunk_length_s=30, device=device)\ntranscribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n\n# Perform transcription\ntranscription = transcribe(audio)[\"text\"]\n\n# Define the filename for the transcript\ntranscript_file = \"/kaggle/working/sampletranscript.txt\"\n\n# Write the transcription to a file\nwith open(transcript_file, \"w\", encoding=\"utf-8\") as file:\n    file.write(transcription)\n\nprint(\"Transcription saved to:\", transcript_file)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:25:15.992074Z","iopub.execute_input":"2024-04-22T22:25:15.993365Z","iopub.status.idle":"2024-04-22T22:25:19.834230Z","shell.execute_reply.started":"2024-04-22T22:25:15.993328Z","shell.execute_reply":"2024-04-22T22:25:19.833212Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Transcription saved to: /kaggle/working/sampletranscript.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import pipeline\n\n# Path to the audio file to be transcribed\naudio_file = \"/kaggle/working/audiowav/01-00321-01.wav\"\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Create an ASR pipeline\ntranscribe = pipeline(task=\"automatic-speech-recognition\", model=\"vasista22/whisper-hindi-small\", chunk_length_s=30, device=device)\ntranscribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n\n# Perform transcription\ntranscription = transcribe(audio_file)[\"text\"]\n\n# Define the filename for the transcript\ntranscript_file = \"/kaggle/working/sample2transcript.txt\"\n\n# Write the transcription to a file\nwith open(transcript_file, \"w\", encoding=\"utf-8\") as file:\n    file.write(f\"{os.path.basename(audio_file)} {transcription}\\n\")\n\nprint(\"Transcription saved to:\", transcript_file)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:12:08.059366Z","iopub.execute_input":"2024-04-22T23:12:08.059798Z","iopub.status.idle":"2024-04-22T23:12:12.163670Z","shell.execute_reply.started":"2024-04-22T23:12:08.059768Z","shell.execute_reply":"2024-04-22T23:12:12.162696Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Transcription saved to: /kaggle/working/sample2transcript.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -r /kaggle/working/samplewav","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:21:20.588781Z","iopub.execute_input":"2024-04-22T23:21:20.589529Z","iopub.status.idle":"2024-04-22T23:21:21.747673Z","shell.execute_reply.started":"2024-04-22T23:21:20.589493Z","shell.execute_reply":"2024-04-22T23:21:21.746063Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment\nimport os\n\n# Path to the folder containing the audio files\naudio_folder = \"/kaggle/input/sampled\"\n# Path to the folder where you want to save the WAV files\noutput_folder = \"samplewav\"\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Iterate over all audio files in the input folder\nfor filename in os.listdir(audio_folder):\n    if filename.endswith(\".mp3\"):  # Assuming all files are in MP3 format\n        # Load the audio file\n        audio = AudioSegment.from_file(os.path.join(audio_folder, filename))\n        # Set the output file name\n        output_filename = os.path.splitext(filename)[0] + \".wav\"\n        # Export the audio file as WAV\n        audio.export(os.path.join(output_folder, output_filename), format=\"wav\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:21:30.592750Z","iopub.execute_input":"2024-04-22T23:21:30.593679Z","iopub.status.idle":"2024-04-22T23:21:32.191610Z","shell.execute_reply.started":"2024-04-22T23:21:30.593636Z","shell.execute_reply":"2024-04-22T23:21:32.190649Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport torch\nfrom transformers import pipeline\n\n# Path to the folder containing audio files\naudio_folder = \"/kaggle/working/samplewav\"\n\n# Get a list of all audio files in the folder\naudio_files = glob.glob(os.path.join(audio_folder, \"*.wav\"))\n\n# Initialize the ASR pipeline\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntranscribe = pipeline(\n    task=\"automatic-speech-recognition\",\n    model=\"vasista22/whisper-hindi-small\",\n    chunk_length_s=30,\n    device=device\n)\ntranscribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n\n# Define the filename for the single transcript file\ntranscript_file = \"/kaggle/working/all_transcriptions.txt\"\n\n# Transcribe each audio file and append the transcription to the single file\nwith open(transcript_file, \"w\", encoding=\"utf-8\") as file:\n    for audio_file in audio_files:\n        # Perform transcription\n        transcription = transcribe(audio_file)[\"text\"]\n        \n        # Write the transcription to the single file\n        file.write(f\"{os.path.basename(audio_file)} {transcription}\\n\")\n\nprint(\"All transcriptions saved to:\", transcript_file)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:23:38.391304Z","iopub.execute_input":"2024-04-22T23:23:38.391685Z","iopub.status.idle":"2024-04-22T23:24:14.148615Z","shell.execute_reply.started":"2024-04-22T23:23:38.391656Z","shell.execute_reply":"2024-04-22T23:24:14.147389Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"All transcriptions saved to: /kaggle/working/all_transcriptions.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Calculate WER","metadata":{}},{"cell_type":"code","source":"!pip install asr-evaluation","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:39:52.850064Z","iopub.execute_input":"2024-04-22T23:39:52.850916Z","iopub.status.idle":"2024-04-22T23:40:07.596243Z","shell.execute_reply.started":"2024-04-22T23:39:52.850865Z","shell.execute_reply":"2024-04-22T23:40:07.594786Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Collecting asr-evaluation\n  Downloading asr_evaluation-2.0.4-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: edit-distance in /opt/conda/lib/python3.10/site-packages (from asr-evaluation) (1.0.6)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from asr-evaluation) (2.4.0)\nDownloading asr_evaluation-2.0.4-py3-none-any.whl (9.1 kB)\nInstalling collected packages: asr-evaluation\nSuccessfully installed asr-evaluation-2.0.4\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install editdistance","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:51:12.104940Z","iopub.execute_input":"2024-04-22T23:51:12.105463Z","iopub.status.idle":"2024-04-22T23:51:26.476547Z","shell.execute_reply.started":"2024-04-22T23:51:12.105427Z","shell.execute_reply":"2024-04-22T23:51:26.475346Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Collecting editdistance\n  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nDownloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: editdistance\nSuccessfully installed editdistance-0.8.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import editdistance\n\ndef calculate_wer(hypothesis_file, reference_file):\n    with open(hypothesis_file, 'r', encoding='utf-8') as f:\n        hypothesis = f.read().strip().split()\n\n    with open(reference_file, 'r', encoding='utf-8') as f:\n        reference = f.read().strip().split()\n\n    wer = editdistance.eval(hypothesis, reference) / len(reference)\n    return wer\n\nhypothesis_file = '/kaggle/input/word-error-rate/all_transcriptions.txt'\nreference_file = '/kaggle/input/word-error-rate/sampletrans.txt'\n\nwer = calculate_wer(hypothesis_file, reference_file)\nprint(f'Word Error Rate: {wer}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:51:35.290869Z","iopub.execute_input":"2024-04-22T23:51:35.291773Z","iopub.status.idle":"2024-04-22T23:51:35.314581Z","shell.execute_reply.started":"2024-04-22T23:51:35.291736Z","shell.execute_reply":"2024-04-22T23:51:35.313416Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Word Error Rate: 0.3017241379310345\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}